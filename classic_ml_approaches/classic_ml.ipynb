{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic Machine Learning approaches #\n",
    "\n",
    "In the following jupyter notebook two standard types of machine learning models will be trained: Logistic Regression and Support Vector Machine.\n",
    "Also the two vectorization methods Word2Vec and TF-IDF will be used for vectorizing the data. So by combining the two models with the two vectorization methods we get four different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the training and test data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files into DataFrames\n",
    "training_data = pd.read_csv('../data/balanced_2_1_ratio.csv')\n",
    "test_data = pd.read_csv('../data/valid_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6063cac387260c02</td>\n",
       "      <td>Kimchi,\\nthats not advertising. Its the artist...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad17dbfea78f651</td>\n",
       "      <td>I am a little surprised and shocked at the ton...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5eae46b6e87b85ac</td>\n",
       "      <td>Barring a citation of course, no. A religion o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8f079550cbe1980e</td>\n",
       "      <td>If someone does end up putting that sock stuff...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0332f7a0090832c1</td>\n",
       "      <td>Hi, a pleasure, I'm fascinated by coal mines, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  6063cac387260c02  Kimchi,\\nthats not advertising. Its the artist...      1   \n",
       "1  bad17dbfea78f651  I am a little surprised and shocked at the ton...      0   \n",
       "2  5eae46b6e87b85ac  Barring a citation of course, no. A religion o...      0   \n",
       "3  8f079550cbe1980e  If someone does end up putting that sock stuff...      0   \n",
       "4  0332f7a0090832c1  Hi, a pleasure, I'm fascinated by coal mines, ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        1       0       1              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the first five elements of the DataFrame\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48670</th>\n",
       "      <td>21b56461d4b61538</td>\n",
       "      <td>\"\\nThe \"\"lead too short\"\" tag was needed, but ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48671</th>\n",
       "      <td>bd78368bd6ba879e</td>\n",
       "      <td>\"\\n\\n Good For A Laugh \\n\\nAlthough not one bi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48672</th>\n",
       "      <td>c98631699c9ff7ff</td>\n",
       "      <td>\"\\nwhy don´t you just get \"\"high\"\"? if not, I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48673</th>\n",
       "      <td>53aa1ef318a2ce3b</td>\n",
       "      <td>GENRE \\n\\nhere is the source that they make ra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48674</th>\n",
       "      <td>1404a1d8219bf4bf</td>\n",
       "      <td>———————————\\nHahahah get fucked filthy mudslim...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                       comment_text  \\\n",
       "48670  21b56461d4b61538  \"\\nThe \"\"lead too short\"\" tag was needed, but ...   \n",
       "48671  bd78368bd6ba879e  \"\\n\\n Good For A Laugh \\n\\nAlthough not one bi...   \n",
       "48672  c98631699c9ff7ff  \"\\nwhy don´t you just get \"\"high\"\"? if not, I ...   \n",
       "48673  53aa1ef318a2ce3b  GENRE \\n\\nhere is the source that they make ra...   \n",
       "48674  1404a1d8219bf4bf  ———————————\\nHahahah get fucked filthy mudslim...   \n",
       "\n",
       "       toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "48670      0             0        0       0       0              0  \n",
       "48671      1             0        0       0       0              0  \n",
       "48672      0             0        0       0       0              0  \n",
       "48673      0             0        0       0       0              0  \n",
       "48674      1             0        1       0       1              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the last five elements of the DataFrame\n",
    "training_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the row \"toxic\": [1 0]\n",
      "Unique values in the row \"severe_toxic\": [0 1]\n",
      "Unique values in the row \"obscene\": [1 0]\n",
      "Unique values in the row \"threat\": [0 1]\n",
      "Unique values in the row \"insult\": [1 0]\n",
      "Unique values in the row \"indentity_hate\": [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Showing all unique values in the classification rows\n",
    "print(f\"Unique values in the row \\\"toxic\\\": {training_data['toxic'].unique()}\")\n",
    "print(f\"Unique values in the row \\\"severe_toxic\\\": {training_data['severe_toxic'].unique()}\")\n",
    "print(f\"Unique values in the row \\\"obscene\\\": {training_data['obscene'].unique()}\")\n",
    "print(f\"Unique values in the row \\\"threat\\\": {training_data['threat'].unique()}\")\n",
    "print(f\"Unique values in the row \\\"insult\\\": {training_data['insult'].unique()}\")\n",
    "print(f\"Unique values in the row \\\"indentity_hate\\\": {training_data['identity_hate'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading neccesary NLTK ressources ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/vinaysanga/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vinaysanga/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vinaysanga/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"Proprocessing the comments of the raw data\"\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # removing usernames starting with '@'\n",
    "    text = re.sub(r'@ ?\\w+', '', text)\n",
    "    # removing URL's\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    # removing the substring \"quot\", which is an HTML entity for double quotation (\"\")\n",
    "    text = re.sub(r'&quot', '', text)\n",
    "    # removing all special characters\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # removing all digits\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    # Join the tokens back into a single string\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies the preprocessing function to all comments \n",
    "training_data['comment_text'] = training_data['comment_text'].apply(preprocess_text)\n",
    "test_data['comment_text'] = test_data['comment_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     id                                       comment_text  \\\n",
      "0      6063cac387260c02  kimchi thats advertising artist bio artist c k...   \n",
      "1      bad17dbfea78f651  little surprised shocked tone aloan follow lar...   \n",
      "2      5eae46b6e87b85ac  barring citation course religion religious sec...   \n",
      "3      8f079550cbe1980e  someone end putting sock stuff tell page right...   \n",
      "4      0332f7a0090832c1  hi pleasure fascinated coal mine hope done ok ...   \n",
      "...                 ...                                                ...   \n",
      "48670  21b56461d4b61538  lead short tag needed started tampering table ...   \n",
      "48671  bd78368bd6ba879e  good laugh although one bit encyclopaedic natu...   \n",
      "48672  c98631699c9ff7ff  get high give every video thumb write bad comment   \n",
      "48673  53aa1ef318a2ce3b       genre source make rapcore rap rock rap metal   \n",
      "48674  1404a1d8219bf4bf                 hahahah get fucked filthy mudslime   \n",
      "\n",
      "       toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0          1             0        1       0       1              0  \n",
      "1          0             0        0       0       0              0  \n",
      "2          0             0        0       0       0              0  \n",
      "3          0             0        0       0       0              0  \n",
      "4          0             0        0       0       0              0  \n",
      "...      ...           ...      ...     ...     ...            ...  \n",
      "48670      0             0        0       0       0              0  \n",
      "48671      1             0        0       0       0              0  \n",
      "48672      0             0        0       0       0              0  \n",
      "48673      0             0        0       0       0              0  \n",
      "48674      1             0        1       0       1              0  \n",
      "\n",
      "[48675 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     id                                       comment_text  \\\n",
      "0      0001ea8717f6de06  thank understanding think highly would revert ...   \n",
      "1      000247e83dcc1211                             dear god site horrible   \n",
      "2      0002f87b16116a7f  somebody invariably try add religion really me...   \n",
      "3      0003e1cccfd5a40a  say right type type institution needed case th...   \n",
      "4      00059ace3e3e9a53  adding new product list make sure relevant add...   \n",
      "...                 ...                                                ...   \n",
      "63973  fff8f64043129fa2  jerome see never got around surprised looked e...   \n",
      "63974  fff9d70fe0722906        lucky bastard heh famous kida envy congrats   \n",
      "63975  fffa8a11c4378854                      shame want speak gay romanian   \n",
      "63976  fffac2a094c8e0e2  mel gibson nazi bitch make shitty movie much b...   \n",
      "63977  fffb5451268fb5ba  unicorn lair discovery supposedly unicorn lair...   \n",
      "\n",
      "       toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0          0             0        0       0       0              0  \n",
      "1          0             0        0       0       0              0  \n",
      "2          0             0        0       0       0              0  \n",
      "3          0             0        0       0       0              0  \n",
      "4          0             0        0       0       0              0  \n",
      "...      ...           ...      ...     ...     ...            ...  \n",
      "63973      0             0        0       0       0              0  \n",
      "63974      0             0        0       0       0              0  \n",
      "63975      0             0        0       0       0              0  \n",
      "63976      1             0        1       0       1              0  \n",
      "63977      0             0        0       0       0              0  \n",
      "\n",
      "[63978 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model with Word2Vec vectorization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.45      0.79      0.58      6090\n",
      " severe_toxic       0.20      0.24      0.22       367\n",
      "      obscene       0.58      0.62      0.60      3691\n",
      "       threat       0.30      0.18      0.23       211\n",
      "       insult       0.53      0.51      0.52      3427\n",
      "identity_hate       0.41      0.23      0.29       712\n",
      "\n",
      "    micro avg       0.48      0.63      0.55     14498\n",
      "    macro avg       0.41      0.43      0.40     14498\n",
      " weighted avg       0.49      0.63      0.54     14498\n",
      "  samples avg       0.07      0.06      0.06     14498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinaysanga/Study/ML4MDE/v2/toxic-comments-classifier/test/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vinaysanga/Study/ML4MDE/v2/toxic-comments-classifier/test/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/vinaysanga/Study/ML4MDE/v2/toxic-comments-classifier/test/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Tokenize the texts\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "# Function to calculate the vector of a text\n",
    "def vectorize_text(tokens, model):\n",
    "    word_vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)  # Return a zero vector if no words are in the model\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Separate the text and labels\n",
    "y_train = training_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "X_train = training_data['comment_text']\n",
    "y_test = test_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "X_test = test_data['comment_text']\n",
    "\n",
    "# Apply tokenization to all comments\n",
    "X_train_tokens = X_train.apply(tokenize)\n",
    "X_test_tokens = X_test.apply(tokenize)\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model_w2v = Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Vectorize the texts\n",
    "X_train_vec = np.array([vectorize_text(tokens, model_w2v) for tokens in X_train_tokens])\n",
    "X_test_vec = np.array([vectorize_text(tokens, model_w2v) for tokens in X_test_tokens])\n",
    "\n",
    "# Multi-output classification (one classification for each category)\n",
    "model_lr_w2v = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_lr_w2v.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_lr_w2v.predict(X_test_vec)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 1\n",
      "severe_toxic: 0\n",
      "obscene: 1\n",
      "threat: 0\n",
      "insult: 1\n",
      "identity_hate: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Test model_lr_w2v with an example comment\"\"\"\n",
    "def get_output_from_model_lr_w2v(model : any, model_vec : any, comment : str)->list:\n",
    "    \"Gets the output from model_lr_w2v and returns it\"\n",
    "    input = [vectorize_text(tokenize(comment),model_vec)]\n",
    "    output = model.predict(input)\n",
    "    toxic_parameters = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    for i in range(len(output[0])):\n",
    "        print(f\"{toxic_parameters[i]}: {output[0][i]}\")  \n",
    "    return output\n",
    "\n",
    "example_comment = \"You are low key stupid\"\n",
    "get_output_from_model_lr_w2v(model_lr_w2v, model_w2v, example_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine with Word2Vec vectorization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "def vectorize_text(tokens, model):\n",
    "    \"Use word2vec model for vectorization\"\n",
    "    word_vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)  # Return a zero vector if no words are in the model\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Separate the text and labels\n",
    "y_train = training_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "X_train = training_data['comment_text']\n",
    "y_test = test_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "X_test = test_data['comment_text']\n",
    "\n",
    "# Apply tokenization to all comments\n",
    "X_train_tokens = X_train.apply(tokenize)\n",
    "X_test_tokens = X_test.apply(tokenize)\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model_w2v = Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Vectorize the texts\n",
    "X_train_vec = np.array([vectorize_text(tokens, model_w2v) for tokens in X_train_tokens])\n",
    "X_test_vec = np.array([vectorize_text(tokens, model_w2v) for tokens in X_test_tokens])\n",
    "\n",
    "# Multi-output classification with SVM (one classification for each category)\n",
    "model_svm_w2v = MultiOutputClassifier(SVC(kernel='linear', C=1))  # SVM with a linear kernel and regularization C=1\n",
    "model_svm_w2v.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_svm_w2v.predict(X_test_vec)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 1\n",
      "severe_toxic: 0\n",
      "obscene: 1\n",
      "threat: 0\n",
      "insult: 1\n",
      "identity_hate: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Test model_svm_w2v with an example comment\"\"\"\n",
    "\n",
    "def get_output_from_model_svm_w2v(model : any, model_vec : any, comment : str)->list:\n",
    "    \"Gets the output from model_svm_w2v and returns it\"\n",
    "    input = [vectorize_text(tokenize(comment),model_vec)]\n",
    "    output = model.predict(input)\n",
    "    toxic_parameters = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    for i in range(len(output[0])):\n",
    "        print(f\"{toxic_parameters[i]}: {output[0][i]}\")  \n",
    "    return output\n",
    "\n",
    "example_comment = \"You are low key stupid\"\n",
    "get_output_from_model_svm_w2v(model_svm_w2v, model_w2v, example_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model with TF-IDF vectorization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tfidf_vectorizer\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Vectorize the comments using TF-IDF\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m create_tfidf_vectorizer(\u001b[43mtraining_data\u001b[49m)\n\u001b[1;32m     16\u001b[0m X_train \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(training_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list())\n\u001b[1;32m     17\u001b[0m X_test \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def create_tfidf_vectorizer(data : pd.core.frame.DataFrame)->any:\n",
    "    \"Creates the tf-idf vectorizer and returns it\"\n",
    "    vectorizer = TfidfVectorizer(max_features=15000, min_df=2, max_df=0.8)\n",
    "    tfidf_vectorizer = vectorizer.fit(data[\"comment_text\"].to_list())\n",
    "    return tfidf_vectorizer\n",
    "\n",
    "# Vectorize the comments using TF-IDF\n",
    "tfidf_vectorizer = create_tfidf_vectorizer(training_data)\n",
    "X_train = tfidf_vectorizer.transform(training_data[\"comment_text\"].to_list())\n",
    "X_test = tfidf_vectorizer.transform(test_data[\"comment_text\"].to_list())\n",
    "\n",
    "# Define the target variables\n",
    "y_train = training_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "y_test = test_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "# Create and train the model\n",
    "model_lr_tfidf = MultiOutputClassifier(LogisticRegression(max_iter=1000, random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model_lr_tfidf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_lr_tfidf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 1\n",
      "severe_toxic: 0\n",
      "obscene: 0\n",
      "threat: 0\n",
      "insult: 1\n",
      "identity_hate: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test model_lr_tfidf with an example comment\"\"\"\n",
    "def get_output_from_model_lr_tfidf(model_lr_tfidf : any, tfidf_vectorizer : any, comment : str)->list:\n",
    "    \"Gets the output from model_lr_tfidf and returns it\"\n",
    "    tfidf_matrix_comment = tfidf_vectorizer.transform([comment])\n",
    "    output = model_lr_tfidf.predict(tfidf_matrix_comment)\n",
    "    toxic_parameters = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    for i in range(len(output[0])):\n",
    "        print(f\"{toxic_parameters[i]}: {output[0][i]}\")   \n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "example_comment = \"You are low key stupid\"\n",
    "result = get_output_from_model_lr_tfidf(model_lr_tfidf, tfidf_vectorizer, example_comment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine with TF-IDF vectorization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tfidf_vectorizer\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Vectorize the comments using TF-IDF\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m create_tfidf_vectorizer(\u001b[43mtraining_data\u001b[49m)\n\u001b[1;32m     15\u001b[0m X_train \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(training_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list())\n\u001b[1;32m     16\u001b[0m X_test \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def create_tfidf_vectorizer(data : pd.core.frame.DataFrame)->any:\n",
    "    \"Creates the tf-idf vectorizer and returns it\"\n",
    "    vectorizer = TfidfVectorizer(max_features=15000, min_df=2, max_df=0.8)\n",
    "    tfidf_vectorizer = vectorizer.fit(data[\"comment_text\"].to_list())\n",
    "    return tfidf_vectorizer\n",
    "\n",
    "# Vectorize the comments using TF-IDF\n",
    "tfidf_vectorizer = create_tfidf_vectorizer(training_data)\n",
    "X_train = tfidf_vectorizer.transform(training_data[\"comment_text\"].to_list())\n",
    "X_test = tfidf_vectorizer.transform(test_data[\"comment_text\"].to_list())\n",
    "\n",
    "# Define the target variables\n",
    "y_train = training_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "y_test = test_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "# Create and train the model\n",
    "model_svm_tfidf = MultiOutputClassifier(SVC(kernel='linear', C=1, random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model_svm_tfidf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_svm_tfidf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 1\n",
      "severe_toxic: 0\n",
      "obscene: 0\n",
      "threat: 0\n",
      "insult: 1\n",
      "identity_hate: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test model_svm_tfidf with an example comment\"\"\"\n",
    "def get_output_from_model_svm_tfidf(model_svm_tfidf : any, tfidf_vectorizer : any, comment : str)->str:\n",
    "    \"Gets the output from model_svm_tfidf and returns it\"\n",
    "    tfidf_matrix_comment = tfidf_vectorizer.transform([comment])\n",
    "    output = model_svm_tfidf.predict(tfidf_matrix_comment)\n",
    "    toxic_parameters = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    for i in range(len(output[0])):\n",
    "        print(f\"{toxic_parameters[i]}: {output[0][i]}\") \n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "example_comment = \"You are low key stupid\"\n",
    "result = get_output_from_model_svm_tfidf(model_svm_tfidf, tfidf_vectorizer, example_comment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
