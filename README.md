# Toxic Comments Classifier

This project implements a machine learning system for classifying toxic comments in text. It includes both classical machine learning approaches and modern LLM-based solutions.

## Project Structure

- `classic_ml_approaches/`: Implementation of traditional machine learning models
- `data/`: Dataset storage and preprocessing scripts
- `llm/`: Large Language Model implementations and experiments
  - `GPU Run.ipynb`: Notebook for GPU-based model training
  - `trainer.py`: Training utilities and functions
  - `test.py`: Testing and evaluation scripts

## Getting Started

1. Clone the repository
2. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

## Features

- Multiple model approaches (classical ML and LLMs)
- GPU support for model training
- Comprehensive evaluation metrics
- Modular codebase structure

## Requirements

The project dependencies are listed in `requirements.txt`. Use Python 3.7+ for best compatibility.

## Usage

1. Prepare your data in the `data/` directory
2. Choose between classical ML approaches or LLM-based solutions
3. Run the appropriate training scripts
4. Use the trained models for inference

## License

This project is open source and available under the MIT License.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
